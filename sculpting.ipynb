{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81efb18b-2469-4c78-9113-1289cba7a310",
   "metadata": {},
   "source": [
    "# Manifold Sculpting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7288a54d-7e95-4ab4-a486-6a009644360b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6babfad-5bef-4b05-b46c-919e3f53acee",
   "metadata": {},
   "source": [
    "### Compute distances"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4eec3c27-ece7-4562-9443-246d53f00962",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Dumb way\n",
    "# troviamo i 1i k vicini\n",
    "scarti = p*torch.ones_like(data) - data\n",
    "dist_sq = scarti*scarti\n",
    "dist_sq = dist_sq.sum(dim=p_size_idx)\n",
    "\n",
    "# sort the points\n",
    "dist_sq, indices = torch.sort(dist_sq)\n",
    "print(dist_sq)\n",
    "# keep the first k (without the point itself)\n",
    "kneighb = indices[1:k+1]\n",
    "dist = torch.sqrt(dist_sq[1:k+1])\n",
    "\n",
    "print(kneighb)\n",
    "print(dist_sq[1:k+1])\n",
    "print(dist)\n",
    "# tutto qsto va in 1 ciclo sui .i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d153b71-f67d-4891-828d-dee587fb29bf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Test cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7619254b-b03a-4370-a3fd-66fab2f6241e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6)\n",
      "tensor([2])\n"
     ]
    }
   ],
   "source": [
    "k = 2\n",
    "data = torch.Tensor([[1,1],[7,7],[9,9],[12,12], [5,5], [2,2]])\n",
    "p = data[2]\n",
    "sigma = 0.1\n",
    "n_dim = 1\n",
    "scale_factor = 1 # at first\n",
    "\n",
    "data_size = torch.tensor(data.size())\n",
    "m = data_size[0] # number of data points\n",
    "p_size = data_size[1:] # size of the single datapoint\n",
    "p_size0 = p_size - torch.ones_like(p_size) # to be used for indexing\n",
    "print(m)\n",
    "print(p_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0a07a21b-14ad-4252-aa1b-b12f3cd976d1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Test cell\n",
    "a = torch.Tensor([1,2])\n",
    "b = torch.Tensor([2,3])\n",
    "c = a@b\n",
    "d = c.item()\n",
    "a.tolist()\n",
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3271f0a4-bd63-47f4-9f52-e61e09f1c3cd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7071, 0.7071])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.7854)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Test cell\n",
    "from math import acos\n",
    "a = torch.Tensor([0,1])\n",
    "b = torch.Tensor([1,1])\n",
    "a /= torch.norm(a)\n",
    "b /= torch.norm(b)\n",
    "print(b)\n",
    "c = torch.acos(a@b)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "134da2b7-f53a-4f60-a2e9-d7b3369eba21",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.3028, 3.0000, 0.6972])\n",
      "tensor([[ 0.2898,  0.0000, -0.9571],\n",
      "        [ 0.9571,  0.0000,  0.2898],\n",
      "        [ 0.0000,  1.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "## Test cell\n",
    "a = torch.Tensor([[1,1,0],\n",
    "                  [1,4,0],\n",
    "                  [0,0,3]])\n",
    "eigenval, eigenvec = torch.linalg.eigh(-a)\n",
    "eigenval = -eigenval\n",
    "print(eigenval)\n",
    "print(eigenvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ad665670-05be-456e-acce-f624e3b566be",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "che tavanata\n",
      "ush\n",
      "ush\n"
     ]
    }
   ],
   "source": [
    "## Test cell\n",
    "a = [1,2]\n",
    "if [0]:\n",
    "    print(\"che tavanata\")\n",
    "while a:\n",
    "    a.pop(0)\n",
    "    print(\"ush\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8657c5fe-44e5-4d26-9583-7e2ca09d17c3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2],\n",
      "        [3]])\n",
      "tensor([3.])\n",
      "tensor([8.])\n"
     ]
    }
   ],
   "source": [
    "## Test cell\n",
    "a = torch.Tensor([[1,2,3,4],[5,6,7,8]])\n",
    "indx = torch.multinomial(a, num_samples=1) # replacement?\n",
    "print(indx)\n",
    "print(a[0,indx[0]])\n",
    "print(a[1,indx[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccf400f-8e27-427b-a89e-8ba750601c46",
   "metadata": {},
   "source": [
    "# Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58a9e7c7-6e3e-4222-bb3d-fae30d3a1ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManifoldSculpting():\n",
    "    ''' \n",
    "    Dependencies: import torch\n",
    "    '''\n",
    "    def __init__(self, k=5, n_dim=2, niter=100, sigma=0.99, patience=30): # rotate = True\n",
    "        # Implementation of the Manifold Sculpting algorithm in PyTorch\n",
    "\n",
    "        # Hyperparameters of the algorithm\n",
    "        # Only torch.tensor()\n",
    "        self.k = k                    # -- number of neighbors considered\n",
    "        self.n_dim = n_dim            # -- dimension of the searched manifold\n",
    "        self.niter = niter            # -- 1st stopping criterion for the iterative cicle \n",
    "        self.sigma = sigma            # -- scaling factor at each iteration (for extra dimensions)\n",
    "        self.scale_factor = 1         # -- cumulative scale factor\n",
    "        self.patience = patience      # -- 2nd stopping criterion\n",
    "\n",
    "    def transform(self, data):\n",
    "        ####### MAIN #######\n",
    "\n",
    "        ## ---- Import\n",
    "        # In case of images or weirdly shaped input points\n",
    "        if len(data.size()) > 2:\n",
    "            flatten   = torch.nn.Flatten()\n",
    "            self.data = flatten(data) \n",
    "            # self.original_p_size = data.size[1:]\n",
    "        else:\n",
    "            self.data = data\n",
    "            \n",
    "        self.p_size = self.data.size()[1]   # single point flattenend dimension \n",
    "        self.n_datapoints = data.size()[0]  # int\n",
    "\n",
    "        ## ---- Compute neighbors relations\n",
    "        self.dist, self.neighb    = self.neighb_distance()\n",
    "        self.colinear, self.theta = self.colinear_neighb()\n",
    "        \n",
    "        self.avg_dist = torch.mean(self.dist)\n",
    "\n",
    "        self.nudge = self.avg_dist\n",
    "\n",
    "        ## ---- PCA transform\n",
    "        self.data = self.pca_transform(self.data)\n",
    "        \n",
    "        # Distinguish dimensions to be scaled/preserved\n",
    "        self.preserv_dim = torch.tensor(list(range(self.n_dim)))\n",
    "        self.scaled_dim  = torch.tensor(list(range(self.n_dim, self.p_size)))\n",
    "\n",
    "        ## ---- Iterative transformation\n",
    "        epoch = 1\n",
    "        \n",
    "        # Adjust a bunch of times without comparing errors\n",
    "        while self.scale_factor > 0.01: # can be tuned\n",
    "            mean_error = self.step()\n",
    "            epoch += 1\n",
    "\n",
    "        epochs_since_improvement = 0\n",
    "        best_error = torch.Tensor(float('inf'))\n",
    "\n",
    "        # Continue adjusting, start comparing errors\n",
    "        while (epoch < self.niter) and (epochs_since_improvement < self.patience):\n",
    "            mean_error = self.step()\n",
    "\n",
    "            if mean_error < best_error:\n",
    "                best_error = mean_error\n",
    "                self.best_data  = torch.clone(self.data)\n",
    "                sefl.best_error = best_error\n",
    "                epochs_since_improvement = 0\n",
    "            else:\n",
    "                epochs_since_improvement += 1\n",
    "                \n",
    "            epochs += 1\n",
    "\n",
    "        ## DEBUG and monitoring\n",
    "        self.elapsed_epochs = epoch\n",
    "        self.last_error = mean_error\n",
    "\n",
    "\n",
    "\n",
    "    def neighb_distance(self):\n",
    "        '''\n",
    "        Returns:\n",
    "        - tensor.size() = (n_datapoints, k)\n",
    "          (i,j) hosts the DISTANCE of point i to its j-th neighbor \n",
    "          with distances decreasing in j\n",
    "        - tensor.size() = (n_datapoints, k) \n",
    "          (i,j) hosts the INDEX (relative to self.data) of the j-th neighbor of point i\n",
    "        '''\n",
    "        x2 = self.data * self.data\n",
    "        x2 = x2.sum(axis=1)\n",
    "        data_t = torch.transpose(self.data, 0, 1) # pb in dim >i (es foto...), credo funzioni cmq\n",
    "        xx = self.data@data_t\n",
    "        \n",
    "        all_distances = torch.sqrt( x2 - 2*xx + x2.unsqueeze(dim=1) ) # they have different dimensions, we leverage pytorch default for the operations\n",
    "        \n",
    "        _, indices = torch.sort(dist)\n",
    "\n",
    "        kneighb = indices[:, 1:self.k+1]\n",
    "        all_distances   = torch.zeros_like(kneighb)\n",
    "\n",
    "        # Cherry-pick neighbors distances (sorted)\n",
    "        d = []  # For some reason it doesn't allow directly with tensors\n",
    "        for i in range(self.n_datapoints):\n",
    "            d.append( all_distances[kneighb[i][:], i] )\n",
    "        \n",
    "        kdist = torch.reshape( torch.cat( d, 0 ), (-1, self.k) )\n",
    "        \n",
    "        return kdist, kneighb\n",
    "\n",
    "    \n",
    "    def avg_neighb_distance(self):\n",
    "        dist = neighbor_distance(self.data)\n",
    "        avg_dist = torch.mean(dist)\n",
    "        \n",
    "        return avg_dist\n",
    "\n",
    "    def colinear_neighb(self):\n",
    "        '''\n",
    "        For clarity:\n",
    "        Variables with _idx  have values in (0, m-1) (selecting points from self.data)\n",
    "        Variables with _kidx have values in (0, k-1)\n",
    "\n",
    "        Returns:\n",
    "        - tensor.size() = (n_datapoints, k)\n",
    "        (i,j) hosts the ANGLE theta (i-j-l) of the most colinear point l to the couple i-j\n",
    "        - tensor.size() = (n_datapoints, k)\n",
    "        (i,j) hosts the NEIGHBOR INDEX of l with respect to the neighbourhood of j\n",
    "        '''\n",
    "        theta    = torch.ones((self.n_datapoints,self.k))\n",
    "        colinear = torch.ones((self.n_datapoints,self.k))\n",
    "        \n",
    "        # Loop over data points\n",
    "        for i_idx in range(self.n_datapoints):\n",
    "            # Loop over neighbors of i\n",
    "            for j_kidx, j_idx in enumerate(self.neighb[i_idx]):\n",
    "                \n",
    "                p2j = self.data[i_idx] - self.data[j_idx]\n",
    "                p2j /= torch.norm(p2j)\n",
    "        \n",
    "                colinear_kidx =  torch.ones(self.k)\n",
    "                cos_i2l = torch.ones(self.k)\n",
    "                # Loop over neighbor points of j\n",
    "                for l_kidx, l_idx in enumerate(self.neighb[j_idx]):\n",
    "                    \n",
    "                    p2l = self.data[l_idx] - self.data[j_idx]\n",
    "                    p2l /= torch.norm(p2l)\n",
    "                    cos_i2l[l_kidx] = p2l@c2j\n",
    "                    \n",
    "                # Extract the colinear angle and neighbor\n",
    "                cos_max, colinear[i_idx, j_kidx] = torch.max(cos_i2l, dim=0)\n",
    "                theta[i_idx, j_kidx] = torch.acos(cos_max)\n",
    "\n",
    "        return colinear, theta\n",
    "    \n",
    "            \n",
    "    def pca_transform():\n",
    "        '''\n",
    "        Returns\n",
    "        - tensor.size() = (n_datapoints, p_size)\n",
    "          the data linearly transformed to the principal components basis\n",
    "        '''\n",
    "        cov = torch.cov(self.data)\n",
    "        eigenval, eigenvec = torch.linalg.eigh(-cov) # -cov because it outputs sorted descending eigenval\n",
    "        eigenval = -eigenval\n",
    "        pca_data = eigenvec@self.data\n",
    "        \n",
    "        return pca_data\n",
    "        \n",
    "    \n",
    "    def compute_error(self, p, visited):\n",
    "        '''\n",
    "        Parameters:\n",
    "        - p : (int)         index of the point\n",
    "        - visited: (list)   list of already adjusted points\n",
    "        \n",
    "        Returs:\n",
    "        - (float) error relative to the neighbourhood of p\n",
    "        '''\n",
    "        \n",
    "        w = torch.ones(self.k)\n",
    "        for j in range(self.k):\n",
    "            w[j] = 10 if self.neighb[p,j] in visited else 1\n",
    "    \n",
    "        total_err = 0\n",
    "        for i in range(self.k):\n",
    "            # Extract indices\n",
    "            n = self.neighb[p,i].item()\n",
    "            c = self.colinear[p,i].item()\n",
    "\n",
    "            # Compute theta_p2c, the angle in p-n-c\n",
    "            p2n = self.data[p] - self.data[n]\n",
    "            c2n = self.data[c] - self.data[n]\n",
    "            p2n /= torch.norm(p2n)\n",
    "            c2n /= torch.norm(c2n)\n",
    "            theta_p2c = torch.acos(p2n@c2n)\n",
    "\n",
    "            # Compute error\n",
    "            err_dist = .5*(p2n - self.dist[p,i]) / self.avg_dist\n",
    "            err_theta = (theta_p2c - self.theta[p,i])/3.1415926535\n",
    "            \n",
    "            total_err += w[i] * (err_dist*err_dist + err_theta*err_theta)\n",
    "            \n",
    "        return total_err\n",
    "    \n",
    "    \n",
    "    def adjust_point(self, p, visited):\n",
    "        '''\n",
    "        Parameters:\n",
    "        - p: (int) index of the point to be adjusted\n",
    "        - visited: (list) list of already adjusted points in current epoch\n",
    "\n",
    "        Returns:\n",
    "        - number of hill descent steps\n",
    "        - error for the adjusted point\n",
    "        '''\n",
    "        # Slightly randomize the entity of the update\n",
    "        nudge = self.nudge * ( .6 + .4*torch.rand(1).item() ) # float\n",
    "        \n",
    "        s = -1 \n",
    "        improved = True\n",
    "        err = self.compute_error(p, visited)\n",
    "        \n",
    "        while (s<30) and improved:\n",
    "            s += 1\n",
    "            improved = False\n",
    "\n",
    "            ## --- Downhill update\n",
    "            # Loop over dimensions (try the same nudge for all of them)\n",
    "            for d in self.preserv_dim:\n",
    "                \n",
    "                self.data[p,d] += nudge  # Try one direction\n",
    "                new_err = self.compute_error(p, visited)\n",
    "                \n",
    "                if new_err >= err:\n",
    "                    self.data[p,d] -= 2*nudge  # Try in the opposite\n",
    "                    new_err = self.compute_error(p, visited)\n",
    "                    \n",
    "                if new_err >= err:\n",
    "                    self.data[p,d] += nudge # Stay put\n",
    "                    \n",
    "                else:\n",
    "                    err = newerr\n",
    "                    improved = True\n",
    "                    \n",
    "        return s, err\n",
    "\n",
    "\n",
    "    def step(self):\n",
    "        '''\n",
    "        Returns:\n",
    "        - (float) mean error after adjustment\n",
    "        '''\n",
    "        # ---- a)\n",
    "        # (a,b refer to pseudo-code (Fig 2.2) in original paper)\n",
    "        \n",
    "        self.scale_factor *= self.sigma\n",
    "        \n",
    "        # Downscale component along scaled dimensions\n",
    "        self.data[:, self.scaled_dim] *= self.sigma\n",
    "    \n",
    "        # Upscale the component along preserved dimensions\n",
    "        while (self.avg_neighb_distance(self.data) < self.avg_dist): # mi sfugge li senso di qsto criterio\n",
    "            self.data[:, self.preserv_dim] /= self.sigma\n",
    "            \n",
    "        # ---- b)\n",
    "        pr_idx = torch.multinomial(torch.ones(self.n_datapoints), num_samples=1)\n",
    "        # pr = data[rand_indx,:]\n",
    "        \n",
    "        queue_idx = []\n",
    "        queue_idx.append(pr_idx)\n",
    "        visited = []\n",
    "    \n",
    "        step = 0\n",
    "        mean_error = 0\n",
    "        counter = 0\n",
    "        \n",
    "        # while the queue is not empty\n",
    "        while queue_idx:\n",
    "            p = queue_idx.pop(0)\n",
    "            if p in visited:\n",
    "                continue\n",
    "    \n",
    "            # Add p's neighbors in the queue\n",
    "            for n in self.neighb[p]:\n",
    "                queue_indx.append(n)\n",
    "                \n",
    "            s, err = self.adjust_point(p,visited) \n",
    "    \n",
    "            step += s\n",
    "            mean_error += err\n",
    "            counter += 1\n",
    "            visited.append(p)\n",
    "    \n",
    "        mean_error /= counter\n",
    "    \n",
    "        # numbers from author's implementation (weight decay-like)\n",
    "        if step < self.n_datapoints:\n",
    "            self.nudge *= 0.87\n",
    "        else:\n",
    "            self.nudge /= 0.91\n",
    "            \n",
    "        return mean_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9652a43-78e1-4d05-a2f3-1bfe477657d1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Other test cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cf11c6d6-2af8-4ab4-b70f-fa727cf66947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3728734254837036"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+2*torch.rand(1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1ec2d4cd-13bd-4ac7-8298-77f0c76de053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.,  9.])\n",
      "tensor([[ 0.4472, -0.8944],\n",
      "        [-0.8944, -0.4472]])\n",
      "tensor([[ 1., -2.],\n",
      "        [-2., -1.]])\n",
      "tensor([[-0.4472,  0.8944],\n",
      "        [-8.0498, -4.0249]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor([[7,4],\n",
    "                  [4,1]])\n",
    "from math import sqrt\n",
    "eigenval, eigenvec = torch.linalg.eigh(a)\n",
    "# me li restituisce già in base ON\n",
    "# verdetto finale: NN ci vuole ness1 trasposizione di sorta\n",
    "print(eigenval)\n",
    "print(eigenvec)\n",
    "print(eigenvec*sqrt(5))\n",
    "pca_basis = eigenvec@a\n",
    "print(pca_basis)\n",
    "\n",
    "#       cov = torch.cov(self.data)\n",
    "#       eigenval, eigenvec = torch.linalg.eigh(-cov) # Li ordina già in vista dla pca!\n",
    "#       eigenval = -eigenval  # Pké li ordina decrescenti\n",
    "#       pca_data = eigenvec@self.data # È qla giusta o è qla trasposta?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b1c864c4-10a2-4b57-bb51-3f26ae4d92f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0), (1, 4), (2, 2), (3, 7), (4, 1), (5, 6)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [0,4,2,7,1,6]\n",
    "list(enumerate(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8816805e-904c-4860-a696-e13326093959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.],\n",
      "        [17.,  2.]])\n",
      "tensor([[1., 2.],\n",
      "        [1., 2.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor([[1,2],[1,2]])\n",
    "len(a.size())\n",
    "b = torch.clone(a)\n",
    "a[1,0] = 17\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8fc0aada-70cf-46bc-9b58-f36eaed443d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1.])\n",
      "tensor([0., 1.])\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(2)\n",
    "b = torch.tensor([0,1])\n",
    "c = torch.tensor([0,1])\n",
    "print(a)\n",
    "a[0] = torch.acos(b@c)\n",
    "print(a)\n",
    "print(torch.acos(b@c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "05478780-224e-47c0-9231-67f1e4b13af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(20.)\n",
      "tensor(2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor([1,5,20,3])\n",
    "b, index = torch.max(a, dim=0)\n",
    "print(b)\n",
    "print(index)\n",
    "b /= b\n",
    "torch.acos(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4b5e6f-1626-4d4c-8fba-8565e05da692",
   "metadata": {},
   "source": [
    "# Programma dla mattina:\n",
    "- [x] Parti leggendo il pezzo che manca dl paper\n",
    "- [x] CONTROLLA che qlo che hai già scritto funzioni \n",
    "    (cfr con il bro per il senso generale, che le funzioni facciano qlo che ti aspetti con dle test cells)\n",
    "- [x] bisogna finire fit\n",
    "- [x] scrivere adjust point\n",
    "- [x] organizzare tutto in 1 classe\n",
    "\n",
    "## Poi incrociare forte le dita pké funzioni su MNIST\n",
    "\n",
    "- [ ] Genera la manifold con il vae (ridotto a 1 o 2 cifre) e già puoi vedere se le organizzano in modi molto #i\n",
    "- [ ] Prova con 2 cifre (ma qua stiamo già azzardando)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31d66e4-fee7-41e0-a862-0790027ad65c",
   "metadata": {},
   "source": [
    "# Attenti al lupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dc071b2-f74a-43db-845e-07e79facff74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "## Import Dataset (MNIST)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),                             \n",
    "])\n",
    "\n",
    "# train_test_data = torchvision.datasets.MNIST(root='./Data', train=True, download=True, transform=transform)\n",
    "train_data = torchvision.datasets.MNIST(root='./Data', train=True, download=True, transform=transform)\n",
    "val_data  = torchvision.datasets.MNIST(root='./Data', train=False, download=True, transform=transform)\n",
    "\n",
    "#frac = 0.98\n",
    "#train_data, test_data = torch.utils.data.random_split(train_test_data, [frac, 1-frac], generator=torch.Generator().manual_seed(42))\n",
    "print(len(train_data))\n",
    "print(len(  val_data))\n",
    "#print(len( test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0d5fe48-cc13-4a14-ba58-2bd99f154344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:  1694 samples \n",
      "Val   set:  868 samples\n"
     ]
    }
   ],
   "source": [
    "# Filter out images with labels 1 and 7 from the training dataset\n",
    "indices = (train_data.targets == 1) + (train_data.targets == 2) # this has the same length as train_data.targets, filled with 1 and 0s\n",
    "indices[8000:] = False  # Limit the number of images with labels 1 and 7\n",
    "train_data.data, train_data.targets = train_data.data[indices], train_data.targets[indices]\n",
    "\n",
    "# Same thing for the Validation dataset\n",
    "indices = (val_data.targets == 1) + (val_data.targets == 2)\n",
    "indices[4000:] = False\n",
    "val_data.data, val_data.targets = val_data.data[indices], val_data.targets[indices]\n",
    "\n",
    "# Same thing for the Test dataset\n",
    "#indices = (test_data.targets == 1) + (test_data.targets == 7)\n",
    "#indices[4000:] = False\n",
    "#test_data.data, test_data.targets = test_data.data[indices], test_data.targets[indices]\n",
    "\n",
    "print(\"Train set: \", len(train_data.targets), \"samples \\nVal   set: \", len(val_data.targets), \"samples\")\n",
    "#print(\"Train set: \", len(train_data.targets), \"samples \\nVal set: \", len(val_data.targets), \"samples \\nTest set: \", len(test_data.targets), \"samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14b86945-9107-4cb2-8de1-3abad7fdf7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN mi interessano i loaders\n",
    "# Validation qua ha poco senso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40fc557c-bccd-4d7c-8570-f42cd9083b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "sculptor = ManifoldSculpting(k=10) # defaults: k=5, n_dim=2, niter=100, sigma=0.99, patience=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50e81ea-6b09-4b22-8fa2-21ce49e386b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sculptor.transform(train_data)\n",
    "print(f'Epochs: {sculptor.elapsed_epochs}')\n",
    "print(f'Final mean error: {scupltor.last_error}')\n",
    "print(f'Best mean error: {sculptor.best_error}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
