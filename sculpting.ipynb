{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81efb18b-2469-4c78-9113-1289cba7a310",
   "metadata": {},
   "source": [
    "# Manifold Sculpting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7288a54d-7e95-4ab4-a486-6a009644360b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from math import pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7619254b-b03a-4370-a3fd-66fab2f6241e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6)\n",
      "tensor([2])\n"
     ]
    }
   ],
   "source": [
    "k = 2\n",
    "data = torch.Tensor([[1,1],[7,7],[9,9],[12,12], [5,5], [2,2]])\n",
    "p = data[2]\n",
    "sigma = 0.1\n",
    "n_dim = 1\n",
    "scale_factor = 1 # at first\n",
    "\n",
    "data_size = torch.tensor(data.size())\n",
    "m = data_size[0] # number of data points\n",
    "p_size = data_size[1:] # size of the single datapoint\n",
    "p_size0 = p_size - torch.ones_like(p_size) # to be used for indexing\n",
    "print(m)\n",
    "print(p_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6babfad-5bef-4b05-b46c-919e3f53acee",
   "metadata": {},
   "source": [
    "### Compute distances"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4eec3c27-ece7-4562-9443-246d53f00962",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Dumb way\n",
    "# troviamo i 1i k vicini\n",
    "scarti = p*torch.ones_like(data) - data\n",
    "dist_sq = scarti*scarti\n",
    "dist_sq = dist_sq.sum(dim=p_size_idx)\n",
    "\n",
    "# sort the points\n",
    "dist_sq, indices = torch.sort(dist_sq)\n",
    "print(dist_sq)\n",
    "# keep the first k (without the point itself)\n",
    "kneighb = indices[1:k+1]\n",
    "dist = torch.sqrt(dist_sq[1:k+1])\n",
    "\n",
    "print(kneighb)\n",
    "print(dist_sq[1:k+1])\n",
    "print(dist)\n",
    "# tutto qsto va in 1 ciclo sui .i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d153b71-f67d-4891-828d-dee587fb29bf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Test cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0a07a21b-14ad-4252-aa1b-b12f3cd976d1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Test cell\n",
    "a = torch.Tensor([1,2])\n",
    "b = torch.Tensor([2,3])\n",
    "c = a@b\n",
    "d = c.item()\n",
    "a.tolist()\n",
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3271f0a4-bd63-47f4-9f52-e61e09f1c3cd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7071, 0.7071])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.7854)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Test cell\n",
    "from math import acos\n",
    "a = torch.Tensor([0,1])\n",
    "b = torch.Tensor([1,1])\n",
    "a /= torch.norm(a)\n",
    "b /= torch.norm(b)\n",
    "print(b)\n",
    "c = torch.acos(a@b)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "134da2b7-f53a-4f60-a2e9-d7b3369eba21",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.3028, 3.0000, 0.6972])\n",
      "tensor([[ 0.2898,  0.0000, -0.9571],\n",
      "        [ 0.9571,  0.0000,  0.2898],\n",
      "        [ 0.0000,  1.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "## Test cell\n",
    "a = torch.Tensor([[1,1,0],\n",
    "                  [1,4,0],\n",
    "                  [0,0,3]])\n",
    "eigenval, eigenvec = torch.linalg.eigh(-a)\n",
    "eigenval = -eigenval\n",
    "print(eigenval)\n",
    "print(eigenvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ad665670-05be-456e-acce-f624e3b566be",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "che tavanata\n",
      "ush\n",
      "ush\n"
     ]
    }
   ],
   "source": [
    "## Test cell\n",
    "a = [1,2]\n",
    "if [0]:\n",
    "    print(\"che tavanata\")\n",
    "while a:\n",
    "    a.pop(0)\n",
    "    print(\"ush\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8657c5fe-44e5-4d26-9583-7e2ca09d17c3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2],\n",
      "        [3]])\n",
      "tensor([3.])\n",
      "tensor([8.])\n"
     ]
    }
   ],
   "source": [
    "## Test cell\n",
    "a = torch.Tensor([[1,2,3,4],[5,6,7,8]])\n",
    "indx = torch.multinomial(a, num_samples=1) # replacement?\n",
    "print(indx)\n",
    "print(a[0,indx[0]])\n",
    "print(a[1,indx[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccf400f-8e27-427b-a89e-8ba750601c46",
   "metadata": {},
   "source": [
    "# Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a9e7c7-6e3e-4222-bb3d-fae30d3a1ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManifoldSculpting():\n",
    "    ''' \n",
    "    Dependencies: torch, math pi (can be avoided by defining pi)\n",
    "    '''\n",
    "    def __init__(self, k=5, n_dim=2, niter=100, sigma=0.99, patience=30): # rotate = True\n",
    "        # Implementation of the Manifold Sculpting algorithm in PyTorch\n",
    "\n",
    "        # Hyperparameters of the algorithm\n",
    "        # Only torch.tensor()\n",
    "        self.k = k                    # -- number of neighbors considered\n",
    "        self.n_dim = n_dim            # -- dimension of the searched manifold\n",
    "        self.niter = niter            # -- 1st stopping criterion for the iterative cicle \n",
    "        self.sigma = sigma            # -- scaling factor at each iteration (for extra dimensions)\n",
    "        # self.rotate = rotate\n",
    "        self.scale_factor = 1         # -- cumulative scale factor\n",
    "        self.patience = patience      # -- 2nd stopping criterion\n",
    "\n",
    "    def transform(self, data):\n",
    "        ####### MAIN #######\n",
    "\n",
    "        ## ---- Import\n",
    "        # In case of images\n",
    "        if len(data.size()) > 2:\n",
    "            flatten   = nn.Flatten()\n",
    "            self.data = flatten(data) \n",
    "            self.original_p_size = data.size[1:]\n",
    "        else:\n",
    "            self.data = data\n",
    "            \n",
    "        self.p_size = self.data.size()[1]   # single point flattenend dimension \n",
    "        self.n_datapoints = data.size()[0]  # int\n",
    "\n",
    "        ## ---- Compute neighb relations\n",
    "        self.dist, self.neighb    = self.neighb_distance()\n",
    "        self.colinear, self.theta = self.colinear_neighb()\n",
    "        \n",
    "        self.avg_dist = torch.mean(self.dist)\n",
    "\n",
    "        self.nudge = self.avg_dist\n",
    "\n",
    "        ## ---- PCA transform\n",
    "        self.data = self.pca_transform(self.data)\n",
    "        \n",
    "        # Distinguish dimensions to be scaled/preserved\n",
    "        self.preserv_dim = torch.tensor(list(range(self.n_dim)))\n",
    "        self.scaled_dim  = torch.tensor(list(range(self.n_dim, self.p_size)))\n",
    "\n",
    "        ## ---- Iterative transformation\n",
    "        epoch = 1\n",
    "        # Adjust a bunch of times before comparing errors\n",
    "        while self.scale_factor > 0.01: # can be tuned\n",
    "            mean_error = self.step()\n",
    "            epoch += 1\n",
    "\n",
    "        epochs_since_improvement = 0\n",
    "        best_error = torch.Tensor(float('inf'))\n",
    "\n",
    "        # Continue adjusting, start comparing errors\n",
    "        while (epoch < self.niter) and (epochs_since_improvement < self.patience):\n",
    "            mean_error = self.step()\n",
    "\n",
    "            if mean_error < best_error:\n",
    "                best_error = mean_error\n",
    "                self.best_data  = torch.clone(self.data)\n",
    "                sefl.best_error = best_error\n",
    "                epochs_since_improvement = 0\n",
    "            else:\n",
    "                epochs_since_improvement += 1\n",
    "                \n",
    "            epochs += 1\n",
    "\n",
    "        ## DEBUG and monitoring\n",
    "        self.elapsed_epochs = epoch\n",
    "        self.last_error = mean_error\n",
    "\n",
    "\n",
    "\n",
    "    def neighb_distance(self):\n",
    "        '''\n",
    "        Returns:\n",
    "        - tensor.size() = (n_datapoints, k)\n",
    "          (i,j) hosts the DISTANCE of point i to its j-th neighbor \n",
    "          with distances decreasing in j\n",
    "        - tensor.size() = (n_datapoints, k) \n",
    "          (i,j) hosts the INDEX (relative to self.data) of the j-th neighbor of point i\n",
    "        '''\n",
    "        x2 = self.data * self.data\n",
    "        x2 = x2.sum(axis=1)\n",
    "        data_t = torch.transpose(self.data, 0, 1) # pb in dim >i (es foto...), credo funzioni cmq\n",
    "        xx = self.data@data_t\n",
    "        \n",
    "        all_distances = torch.sqrt( x2 - 2*xx + x2.unsqueeze(dim=1) ) # they have different dimensions, we leverage pytorch default for the operations\n",
    "        \n",
    "        _, indices = torch.sort(dist)\n",
    "\n",
    "        kneighb = indices[:, 1:self.k+1]\n",
    "        all_distances   = torch.zeros_like(kneighb)\n",
    "\n",
    "        # Cherry-pick neighbors distances (sorted)\n",
    "        d = []  # For some reason it doesn't allow directly with tensors\n",
    "        for i in range(self.n_datapoints):\n",
    "            d.append( all_distances[kneighb[i][:], i] )\n",
    "        \n",
    "        kdist = torch.reshape( torch.cat( d, 0 ), (-1, self.k) )\n",
    "        \n",
    "        return kdist, kneighb\n",
    "\n",
    "    \n",
    "    def avg_neighb_distance(self):\n",
    "        dist = neighbor_distance(self.data)\n",
    "        avg_dist = torch.mean(dist)\n",
    "        \n",
    "        return avg_dist\n",
    "\n",
    "    def colinear_neighb(self):\n",
    "        '''\n",
    "        For clarity:\n",
    "        Variables with _idx  run from 0 to m-1 (selecting points from self.data)\n",
    "        Variables with _kidx run from 0 to k-1\n",
    "\n",
    "        Returns:\n",
    "        - tensor.size() = (n_datapoints, k)\n",
    "        (i,j) hosts the ANGLE theta (i-j-l) of the most colinear point l to the couple i-j\n",
    "        - tensor.size() = (n_datapoints, k)\n",
    "        (i,j) hosts the NEIGHBOR INDEX of l with respect to the neighbourhood of j\n",
    "        '''\n",
    "        theta    = torch.ones((self.n_datapoints,self.k))\n",
    "        colinear = torch.ones((self.n_datapoints,self.k))\n",
    "        \n",
    "        # Loop over data points\n",
    "        for i_idx in range(self.n_datapoints):\n",
    "            # Loop over neighbors of i\n",
    "            for j_kidx, j_idx in enumerate(self.neighb[i_idx]):\n",
    "                \n",
    "                p2j = self.data[i_idx] - self.data[j_idx]\n",
    "                p2j /= torch.norm(p2j)\n",
    "        \n",
    "                colinear_kidx =  torch.ones(self.k)\n",
    "                cos_i2l = torch.ones(self.k)\n",
    "                # Loop over neighbor points of j\n",
    "                for l_kidx, l_idx in enumerate(self.neighb[j_idx]):\n",
    "                    \n",
    "                    p2l = self.data[l_idx] - self.data[j_idx]\n",
    "                    p2l /= torch.norm(p2l)\n",
    "                    cos_i2l[l_kidx] = p2l@c2j\n",
    "                    \n",
    "                cos, cos_kidx = torch.sort(cos_i2l, descending=True)\n",
    "                \n",
    "                # Extract the colinear angle and neighbor, 0 is max\n",
    "                colinear[i_idx, j_kidx] = cos_kidx[0] \n",
    "                theta[i_idx, j_kidx] = torch.acos(cos[0]).item()\n",
    "\n",
    "        return colinear, theta\n",
    "    \n",
    "        \n",
    "    \n",
    "            \n",
    "    def pca_transform():\n",
    "        cov = torch.cov(self.data)\n",
    "        eigenval, eigenvec = torch.linalg.eigh(-cov) # Li ordina già in vista dla pca!\n",
    "        eigenval = -eigenval  # Pké li ordina decrescenti\n",
    "        pca_data = eigenvec@self.data # È qla giusta o è qla trasposta?\n",
    "        \n",
    "        return pca_data\n",
    "    \n",
    "    def compute_error(self, p, visited):\n",
    "        '''\n",
    "        Parameters:\n",
    "        - p : (int)         index of the point\n",
    "        - visited: (list)   list of already adjusted points\n",
    "        \n",
    "        Returs:\n",
    "        - (float) error relative to the neighbourhood of p\n",
    "        '''\n",
    "        \n",
    "        w = torch.ones(self.k)\n",
    "        for j in range(self.k):\n",
    "            w[j] = 10 if self.neighb[p,j] in visited else 1\n",
    "    \n",
    "        total_err = 0\n",
    "        for i in range(self.k):\n",
    "            # Extract indices\n",
    "            n = self.neighb[p,i].item()\n",
    "            c = self.colinear[p,i].item()\n",
    "\n",
    "            # Compute theta_p2c, the angle in p-n-c\n",
    "            p2n = self.data[p] - self.data[n]\n",
    "            c2n = self.data[c] - self.data[n]\n",
    "            p2n /= torch.norm(p2n)\n",
    "            c2n /= torch.norm(c2n)\n",
    "            theta_p2c = torch.acos(p2n@c2n)\n",
    "\n",
    "            # Compute error\n",
    "            err_dist = .5*(p2n - self.dist[p,i]) / self.avg_dist\n",
    "            err_theta = (theta_p2c - self.theta[p,i])/pi\n",
    "            \n",
    "            total_err += w[i] * (err_dist*err_dist + err_theta*err_theta)\n",
    "            \n",
    "        return total_err\n",
    "    \n",
    "    \n",
    "    \n",
    "    def adjust_point(self, p, visited):\n",
    "        # nudge = self.nudge * ( .6 + .4*torch.rand(1).item() ) # il fratello fa così\n",
    "        nudge = self.nudge\n",
    "        s = -1 \n",
    "        improved = True\n",
    "        err = self.compute_error(p, visited)  # nl'articolo qsto è nl while, ma è meglio così\n",
    "        \n",
    "        while (s<30) and improved:\n",
    "            s += 1\n",
    "            improved = False\n",
    "\n",
    "            ## --- Uphill/Downhill update\n",
    "            for d in self.d_pres:\n",
    "                self.data[p,d] += nudge  # è il passo di cui ci muoviamo\n",
    "                new_err = self.compute_error(p, visited)\n",
    "                \n",
    "                if new_err >= err:\n",
    "                    self.data[p,d] -= 2*nudge  # se nn ci piace andiamo nl'altra direzione (head slap)\n",
    "                    new_err = self.compute_error(p, visited):\n",
    "                    \n",
    "                    if new_err >= err:\n",
    "                        self.data[p,d] += nudge # se nn ci piace torniamo dov'eravamo all'inizio\n",
    "                    # else:\n",
    "                    #     improved = True\n",
    "                else:\n",
    "                    err = newerr\n",
    "                    improved = True\n",
    "                    \n",
    "        return s, err\n",
    "\n",
    "\n",
    "    def step(self):\n",
    "        # ---- a)\n",
    "        # (a,b refer to the pseudo-code (Fig 2.2) in the paper)\n",
    "        \n",
    "        self.scale_factor *= self.sigma\n",
    "        # Downscale component along scaled dimensions\n",
    "        self.data[:, self.scaled_dim] *= self.sigma\n",
    "    \n",
    "        # Upscale the component along preserved dimensions\n",
    "        while (self.avg_neighb_distance(self.data) > self.dist_avg):\n",
    "            self.data[:, self.preserv_dim] /= self.sigma\n",
    "            \n",
    "        # ---- b)\n",
    "        pr_indx = torch.multinomial(torch.ones(self.m), num_samples=1)\n",
    "        # pr = data[rand_indx,:]\n",
    "        \n",
    "        queue_indx = []\n",
    "        queue_indx.append(pr_indx)\n",
    "        visited = []\n",
    "    \n",
    "        steps = 0\n",
    "        mean_error = 0  # mi sfugge a cosa serva...\n",
    "        counter = 0 # mi sfugge a cosa serva...\n",
    "        while queue_indx:  # while the queue is not empty\n",
    "            p = queue_indx.pop(0)\n",
    "            if p in visited:\n",
    "                continue\n",
    "    \n",
    "            # Add p's neighbors in the queue\n",
    "            for n in kneighb[p]:\n",
    "                queue_indx.append(n)\n",
    "                \n",
    "            s, err = adjust_point(p,visited) \n",
    "    \n",
    "            step += s\n",
    "            mean_error += err\n",
    "            counter += 1\n",
    "            visited.append(p)\n",
    "    \n",
    "        mean_error /= counter\n",
    "    \n",
    "        # numbers from author (1 rozzo weight decay, sembra): lo dice a pag 11\n",
    "        if step < self.m:\n",
    "            self.nudge *= 0.87\n",
    "        else:\n",
    "            self.nudge /= 0.91\n",
    "            \n",
    "        return mean_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8816805e-904c-4860-a696-e13326093959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.],\n",
      "        [17.,  2.]])\n",
      "tensor([[1., 2.],\n",
      "        [1., 2.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor([[1,2],[1,2]])\n",
    "len(a.size())\n",
    "b = torch.clone(a)\n",
    "a[1,0] = 17\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8fc0aada-70cf-46bc-9b58-f36eaed443d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1.])\n",
      "tensor([0., 1.])\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(2)\n",
    "b = torch.tensor([0,1])\n",
    "c = torch.tensor([0,1])\n",
    "print(a)\n",
    "a[0] = torch.acos(b@c)\n",
    "print(a)\n",
    "print(b@c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4b5e6f-1626-4d4c-8fba-8565e05da692",
   "metadata": {},
   "source": [
    "# Programma dla mattina:\n",
    "- [x] Parti leggendo il pezzo che manca dl paper\n",
    "- [ ] CONTROLLA che qlo che hai già scritto funzioni \n",
    "    (cfr con il bro per il senso generale, che le funzioni facciano qlo che ti aspetti con dle test cells)\n",
    "- [x] bisogna finire fit\n",
    "- [x] scrivere adjust point\n",
    "- [x] organizzare tutto in 1 classe\n",
    "\n",
    "## Poi incrociare forte le dita pké funzioni su MNIST\n",
    "\n",
    "- [ ] Genera la manifold con il vae (ridotto a 1 o 2 cifre) e già puoi vedere se le organizzano in modi molto #i\n",
    "- [ ] Prova con 2 cifre (ma qua stiamo già azzardando)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
